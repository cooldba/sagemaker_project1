{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Text Classification can be used to solve various use-cases like sentiment analysis, spam detection, hashtag prediction etc. This notebook demonstrates the use of SageMaker BlazingText to perform supervised binary/multi class with single or multi label text classification. BlazingText can train the model on more than a billion words in a couple of minutes using a multi-core CPU or a GPU, while achieving performance on par with the state-of-the-art deep learning text classification algorithms. BlazingText extends the fastText text classifier to leverage GPU acceleration using custom CUDA kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting. If you don't specify a bucket, SageMaker SDK will create a default bucket following a pre-defined naming convention in the same region. \n",
    "- The IAM role ARN used to give SageMaker access to your data. It can be fetched using the **get_execution_role** method from sagemaker python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::420696774360:role/service-role/AmazonSageMaker-ExecutionRole-20181220T094966\n",
      "text-classification-pgullc\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role) # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = 'text-classification-pgullc' # Replace with your own bucket name if needed\n",
    "print(bucket)\n",
    "prefix = 'blazingtext/supervised' #Replace with the prefix under which you want to store the data if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Now we'll download a dataset from the web on which we want to train the text classification model. BlazingText expects a single preprocessed text file with space separated tokens and each line of the file should contain a single sentence and the corresponding label(s) prefixed by \"\\__label\\__\".\n",
    "\n",
    "In this example, let us train the text classification model on the [DBPedia Ontology Dataset](https://wiki.dbpedia.org/services-resources/dbpedia-data-set-2014#2) as done by [Zhang et al](https://arxiv.org/pdf/1509.01626.pdf). The DBpedia ontology dataset is constructed by picking 14 nonoverlapping classes from DBpedia 2014. It has 560,000 training samples and 70,000 testing samples. The fields we used for this dataset contain title and abstract of each Wikipedia article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-12-23 14:20:20--  https://github.com/saurabh3949/Text-Classification-Datasets/raw/master/dbpedia_csv.tar.gz\n",
      "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
      "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/saurabh3949/Text-Classification-Datasets/master/dbpedia_csv.tar.gz [following]\n",
      "--2018-12-23 14:20:20--  https://raw.githubusercontent.com/saurabh3949/Text-Classification-Datasets/master/dbpedia_csv.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.200.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.200.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68431223 (65M) [application/octet-stream]\n",
      "Saving to: ‘dbpedia_csv.tar.gz’\n",
      "\n",
      "dbpedia_csv.tar.gz  100%[===================>]  65.26M  34.5MB/s    in 1.9s    \n",
      "\n",
      "2018-12-23 14:20:23 (34.5 MB/s) - ‘dbpedia_csv.tar.gz’ saved [68431223/68431223]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/saurabh3949/Text-Classification-Datasets/raw/master/dbpedia_csv.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbpedia_csv/\n",
      "dbpedia_csv/test.csv\n",
      "dbpedia_csv/classes.txt\n",
      "dbpedia_csv/train.csv\n",
      "dbpedia_csv/readme.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf dbpedia_csv.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect the dataset and the classes to get some understanding about how the data and the label is provided in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,\"E. D. Abbott Ltd\",\" Abbott of Farnham E D Abbott Limited was a British coachbuilding business based in Farnham Surrey trading under that name from 1929. A major part of their output was under sub-contract to motor vehicle manufacturers. Their business closed in 1972.\"\n",
      "1,\"Schwan-Stabilo\",\" Schwan-STABILO is a German maker of pens for writing colouring and cosmetics as well as markers and highlighters for office use. It is the world's largest manufacturer of highlighter pens Stabilo Boss.\"\n",
      "1,\"Q-workshop\",\" Q-workshop is a Polish company located in Poznań that specializes in designand production of polyhedral dice and dice accessories for use in various games (role-playing gamesboard games and tabletop wargames). They also run an online retail store and maintainan active forum community.Q-workshop was established in 2001 by Patryk Strzelewicz – a student from Poznań. Initiallythe company sold its products via online auction services but in 2005 a website and online store wereestablished.\"\n"
     ]
    }
   ],
   "source": [
    "!head dbpedia_csv/train.csv -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,\"Arkham's Masters of Horror\",\" Arkham's Masters of Horror is an anthology of fantasy and horror stories edited by Peter Ruber. It was released by Arkham House in an edition of approximately 4000 copies in 2000. The book includes an introductory essay by Ruber before each story and about its author. Ruber has drawn criticism from the horror/fantasy community for the hostility with which he introduces some authors within the volume - for instance his accusation that H.P.\"\n",
      "14,\"Curtains for Three\",\" Curtains for Three is a collection of Nero Wolfe mystery novellas by Rex Stout published by the Viking Press in 1951 and itself collected in the omnibus volume Full House (Viking 1955). The book comprises three stories that first appeared in The American Magazine: The Gun with Wings (December 1949) Bullet for One (July 1948) Disguise for Murder (September 1950 as The Twisted Scarf)\"\n",
      "14,\"The Passion of Michel Foucault\",\" The Passion of Michel Foucault is a biography of the French philosopher Michel Foucault authored by the American philosopher James Miller. It was first published in the United States by Simon & Schuster in 1993.Within the book Miller made the claim that Foucault's experiences in the gay sadomasochism community during the time he taught at Berkeley directly influenced his political and philosophical works.\"\n",
      "14,\"Equal Danger\",\" Equal Danger (Italian title: Il contesto) is a 1971 detective novel by Leonardo Sciascia where a police inspector investigating a string of murders finds himself involved in existential political intrigues. Set in an indeterminate country this novel is informed by the corrupt politics and Mafia of Sciascia's experiences in 1970s Sicily.\"\n",
      "14,\"The Vagina Monologues\",\" The Vagina Monologues is an episodic play written by Eve Ensler which ran at the Off Broadway Westside Theatre after a limited run at HERE Arts Center in 1996. Ensler originally starred in the production which was produced by David Stone Nina Essman Dan Markley The Araca Group Willa Shalit and the West Side Theater. When she left the play it was recast with three celebrity monologists.\"\n",
      "14,\"Ingrid Caven (novel)\",\" Ingrid Caven is a 2000 novel by the French writer Jean-Jacques Schuhl. It received the Prix Goncourt.\"\n",
      "14,\"Geophysical Journal International\",\" Geophysical Journal International is a monthly peer-reviewed scientific journal published by Oxford University Press on behalf of the Royal Astronomical Society and the Deutsche Geophysikalische Gesellschaft (German Geophysical Society). The journal published original research papers research notes letters and book reviews. It was established in 1922. The editor-in-chief is Jeannot Trampert (Utrecht University).\"\n",
      "14,\"Wisdom's Daughter\",\" Wisdom's Daughter is the final book in the Ayesha series written by Sir H. Rider Haggard published in 1923 by Doubleday Page and Company.\"\n",
      "14,\"The Princess Diaries Volume VIII: Princess on the Brink\",\" The Princess Diaries Volume VIII: Princess on the Brink released in the United Kingdom as The Princess Diaries: After Eight is a young adult book in the critically acclaimed Princess Diaries series. Written by Meg Cabot it was released in 2007 by Harper Collins Publishers and is the eighth novel in the series.\"\n",
      "14,\"Pacific Standard\",\" Not to be confused with Reese Witherspoon's film production company Pacific Standard.Pacific Standard formerly Miller-McCune is an American magazine.\"\n",
      "14,\"On Giants' Shoulders\",\" On Giants' Shoulders was written in 1998 by Melvyn Bragg. The book was assembled after a series of interviews Bragg had with current scientists about the worlds greatest scientists such as Archimedes Isaac Newton and Einstein. Bragg who brands himself as a non-scientist conducted these interviews on BBC Radio 4 for other non-scientists.\"\n",
      "14,\"View from a Height\",\" View from a Height is a collection of seventeen scientific essays by Isaac Asimov. It was the second of a series of books collecting essays from The Magazine of Fantasy and Science Fiction written between 1959 and 1962. It was first published by Doubleday & Company in 1963.The collection includes the essay By Jove! the source of the Asimov misquote describing the Solar System (besides the Sun) as Jupiter plus debris. The actual quote is 4 planets plus debris.\"\n",
      "14,\"Letters to Felice\",\" Letters to Felice is a book collecting some of Franz Kafka's letters to Felice Bauer from 1912 to 1917. Schocken Books acquired these letters from Felice Bauer in 1955 in addition to roughly half of Kafka's letters to Grete Bloch Bauer's friend. Additional letters to Bloch were acquired at a later date.\"\n",
      "14,\"Lingvisticae Investigationes\",\" Lingvisticae Investigationes: International Journal of Linguistics and Language Resources is a peer-reviewed academic journal of linguistics published by Benjamins. The journal publishes articles book reviews and summaries of PhD theses. Lingvisticae Investigationes publishes 350 pages a year. There is usually a special issue each year. The founder and former editor-in-chief was Maurice Gross (1977–2001).\"\n",
      "14,\"Tom Clancy's Net Force Explorers: Gameprey\",\" Tom Clancy's Net Force Explorers or Net Force Explorers is a series of young adult novels created by Tom Clancy and Steve Pieczenik as a spin-off of the military fiction series Tom Clancy's Net Force.\"\n",
      "14,\"The International Journal of Robotics Research\",\" The International Journal of Robotics Research is a peer-reviewed scientific journal that covers research in the field of robotics on topics from sensors and sensory interpretations to kinematics in motion planning. The journal's editor-in-chief is John M. Hollerbach (University of Utah). It was established in 1982 and is currently published by Sage Publications.\"\n",
      "14,\"Searching for Whitopia\",\" Searching for Whitopia: An Improbable Journey to the Heart of White America is a 2009 non-fiction book by Rich Benjamin.\"\n",
      "14,\"Commentarii de Bello Gallico\",\" Commentarii de Bello Gallico (English: Notebooks about the Gallic War) is Julius Caesar's firsthand account of the Gallic Wars written as a third-person narrative. In it Caesar describes the battles and intrigues that took place in the nine years he spent fighting local armies in Gaul that opposed Roman domination.\"\n",
      "14,\"Okojo-san\",\" Okojo-san (オコジョさん) is a Japanese manga series written and illustrated by Ayumi Uno and serialized in LaLa. The chapters were collected into eight tankōbon volumes by Hakusensha and released from 1996 to 2005. The series is about an ermine living as a pet in a small apartment complex.Okojo-san was adapted into a 51-episode anime series titled Shiawase Sou no Okojo-san (しあわせソウのオコジョさん) by the Japanese animation studio Radix and aired on TV Tokyo from October 2 2001 to September 24 2002.\"\n",
      "14,\"Flash for Freedom!\",\" Flash for Freedom! is a 1971 novel by George MacDonald Fraser. It is the third of the Flashman novels.\"\n",
      "14,\"Blood Rites (novel)\",\" Blood Rites is the 6th book in The Dresden Files Jim Butcher's continuing series about wizard detective Harry Blackstone Copperfield Dresden.\"\n",
      "14,\"Freddy vs. Jason vs. Ash: The Nightmare Warriors\",\" Freddy vs. Jason vs. Ash: The Nightmare Warriors is a six-issue limited series comic book written by Jeff Katz and James Kuhoric with art by Jason Craig. The series was published by Dynamite Entertainment and DC Comics with imprint by Wildstorm beginning in August 2009 and concluding in December 2009. The Nightmare Warriors is a sequel to Freddy vs. Jason vs. Ash which was published in 2007 and was itself a sequel to the 2003 film Freddy vs. Jason.\"\n",
      "14,\"How It Happened\",\" How it happened is a 1506-word short story by the author Sir Arthur Ignatius Conan Doyle first published during the First World War at the end of what may be considered to be the Edwardian era in 1918 but Conan Doyle began writing in the Victorian era. This story is considered to be about wilful masculine pride and could also be recognised as a warning about the perils of driving at night and in an unfamiliar vehicle.\"\n",
      "14,\"Johnny Gone Down\",\" Johnny Gone Down is second novel written by Indian Author Karan Bajaj about an Ivy League Scholar who had a bright future at NASA ahead of him but things seem to take a dramatic turn from an innocent vacation. The protagonist then partakes a series of adventures.[]\"\n",
      "14,\"Al Madina (newspaper)\",\" Al Madina is an Arabic language newspaper published in Jeddah Saudi Arabia. The paper is one of the oldest newspapers published in the country.\"\n",
      "14,\"The Gunslinger and the Dark Man\",\" The Gunslinger and the Dark Man is a short story by Stephen King originally published in The Magazine of Fantasy and Science Fiction in November 1981. In 1982 The Gunslinger and the Dark Man was collected with several other stories King published in The Magazine of Fantasy and Science Fiction as The Dark Tower: The Gunslinger. The Gunslinger and the Dark Man formed the fifth and final chapter of the book and was slightly revised for the inclusion.\"\n",
      "14,\"The Parkersburg News and Sentinel\",\" The Parkersburg News and Sentinel is the primary newspaper in Parkersburg West Virginia United States. It was formed by the merger of the previously separate morning News and afternoon Sentinel on April 25 2009.\"\n",
      "14,\"Empire (Card novel)\",\" Empire (2006) is a speculative fiction novel by Orson Scott Card. It tells the story of a possible second American Civil War this time between the Right Wing and Left Wing in the near future. It is the first of the two books in The Empire duet followed by Hidden Empire with the video game Shadow Complex bridging the two.\"\n",
      "14,\"Borderlands (novel)\",\" Borderlands is a 1991 children's historical novel by author Peter Carter Originally published in the UK in 1990 as Leaving Cheyenne it is a study of the American West in 1871 as seen through the eyes of a 14-year-old boy.\"\n",
      "14,\"Records of the Grand Historian\",\" The Records of the Grand Historian (Taishi gong shu 太史公書 now usually known as the Shiji 史記 – Historical Records) is a comprehensive history of ancient China that covers a 2500-year period from the age of the legendary Yellow Emperor to the reign of Emperor Wu of Han in the 2nd century BC.\"\n",
      "14,\"100 People Who Are Screwing Up America\",\" 100 People Who Are Screwing Up America (and Al Franken is #37) is a non-fiction book by Bernard Goldberg that was published in 2005. The book's central idea is to name and blame a long list of specific individuals for making the United States a far more selfish vulgar and cynical place.\"\n",
      "14,\"The Elements of Java Style\",\" The Elements of Java Style is a book of rules of programming style in the Java computer language. The book was published by Cambridge University Press in January 2000. The book provides conventions for formatting naming documentation programming and packaging.This book is part of a series of books that include The Elements of C# Style and The Elements of C++ Style.\"\n",
      "14,\"Northern News\",\" The Northern News is a newspaper in Kirkland Lake Ontario Canada. It is owned and published by Sun Media.First published in 1922 as the Northern Daily News it was downsized to fit the population in the readership on June 1 2004. It had been a daily newspaper but now only publishes three times a week.On August 28 2012 the online version of Northern News was revamped to include more current events at the local regional and national level.\"\n",
      "14,\"Dark Forces (book)\",\" Dark Forces: New Stories of Suspense and Supernatural Horror is an anthology of 23 original horror stories first published by The Viking Press in 1980 and as a paperback by Bantam Books in 1981. It was edited by New York City literary agent Kirby McCauley. Dark Forces won the World Fantasy award for best anthology/collection in 1981 and is celebrated in an essay by Christopher Golden in Horror: Another 100 Best Books edited by Stephen Jones and Kim Newman.\"\n",
      "14,\"Book of Matches\",\" Book Of Matches is a poetry book written by Simon Armitage first published in 1993 by Faber and Faber. Several poems featured in the book are studied as part of the GCSE English Literature examination in the UK.The book is written in three sections the first (Book of Matches) containing 30 short sonnets. Each is meant to be read within 20 seconds the amount of time it would take for a match to be lit and burn out.\"\n",
      "14,\"Airframe (novel)\",\" Airframe is a novel by American writer Michael Crichton first published in hardcover in 1996 by Knopf and as a paperback in 1997 by Ballantine Books. The plot follows Casey Singleton a quality assurance vice-president at the fictional aerospace manufacturer Norton Aircraft as she investigates an in-flight accident aboard a Norton-manufactured airliner that leaves three passengers dead and fifty-six injured.Airframe remains one of Crichton's few novels to be unadapted to film.\"\n",
      "14,\"1876 (novel)\",\" Gore Vidal's 1876 is the third historical novel in his Narratives of Empire series. It was published in 1976 and details the events of a year described by Vidal himself as probably the low point in our republic's history.\"\n",
      "14,\"Crusade (Destroyermen novel)\",\" Crusade is the second book of the Destroyermen series. MatthewReddy and the crew of USS Walker (DD-163) are reunited with the destroyer USS Mahan (DD-102) and set out to fight the Grik. Reddy and Walker's marine detachment continue training the Lemurians to defend themselves and take the war to the Grik. The Grik have now taken over the ship that was chasing them the Japanese battlecruiser Amagi.\"\n",
      "14,\"The Country of the Blind\",\" The Country of the Blind is a short story written by H. G. Wells. It was first published in the April 1904 issue of The Strand Magazine and included in a 1911 collection of Wells's short stories The Country of the Blind and Other Stories. It is one of Wells's best known short stories and features prominently in literature dealing with blindness.Wells later revised the story with the expanded version first published by an English private printer Golden Cockerel Press in 1939.\"\n",
      "14,\"Justine (Sade)\",\" Justine (or The Misfortunes of Virtue or several other titles: see below) is a classic 1791 novel by Donatien Alphonse François de Sade better known as the Marquis de Sade. There is no standard edition of this text in hardcover having passed into the public domain. The text itself is often incorporated into collections of Sade's work.Justine is set just before the French Revolution in France and tells the story of a young woman who goes under the name of Therese.\"\n",
      "14,\"Professor Shonku (short story collection)\",\" Professor Shonku is a short story collection by Satyajit Ray featuring the eponymous character Professor Shonku. It was first published in India by NewScript Publications Calcutta in 1965. Of the nine short stories that are part of the collection eight had formerly been published in various editions of the periodical magazine Sandesh and one (namely Professor Shonku o Bhoot) in Ashcharya.The collection contains seven stories to which two other were added in later editions.\"\n",
      "14,\"Jennifer Hecate Macbeth William McKinley and Me Elizabeth\",\" Jennifer Hecate Macbeth William McKinley and Me Elizabeth is a children's novel by E. L. Konigsburg. It was published by Atheneum Books in 1967 and next year in the UK by Macmillan under the title Jennifer Hecate Macbeth and Me.Jennifer Hecate was the author's first book published the same year as her second book From the Mixed-Up Files of Mrs. Basil E. Frankweiler.\"\n",
      "14,\"On Pointe\",\" On Pointe is a children's novel written by Lorie Ann Grover published in 2004.It was nominated for the 2006 Dorothy Canfield Fisher Children's Book Award.\"\n",
      "14,\"Wonka Vision\",\" Wonka Vision was an American music magazine. It was founded in 1998 by Justin Luczejko and ceased publication in 2010.\"\n",
      "14,\"Život a dílo skladatele Foltýna\",\" Život a dílo skladatele Foltýna (Life and Work of the Composer Foltýn) is an unfinished Czech novel written by Karel Čapek. It was first published posthumously in 1939. It is a fictional biography of a composer Bedřich Foltýn (pseudonym Beda Folten) who perceives himself as a genius and is hopelessly obsessed with an idea to become a great artist and to write a big opera about Biblical Judith.\"\n",
      "14,\"Journal of British Cinema and Television\",\" The Journal of British Cinema and Television is a triannual academic journal published by Edinburgh University Press in May August and December of each year. It was established in 2004. Themed issues alternate with regular issues and every issue contains papers book reviews interviews and conferences.\"\n",
      "14,\"Canadian Journal of Physics\",\" The Canadian Journal of Physics is a peer-reviewed scientific journal of physics. It was established in 1929. The journal is published monthly by the NRC Research Press and edited by Michael Steinitz (St. Francis Xavier University). It is also affiliated with the Canadian Association of Physicists.\"\n",
      "14,\"Journey to Jupiter\",\" Journey to Jupiter is a juvenile science fiction novel the eighth in Hugh Walters' Chris Godfrey of U.N.E.X.A. series. It was published in the UK by Faber in 1965 and in the US by Criterion Books in 1966.\"\n",
      "14,\"The Green Bible\",\" The Green Bible is an English version of the New Revised Standard Version Bible with a focus on environmental issues and teachings. It was originally published by Harper Bibles on October 7 2008. It is a study Bible featuring essays by N.T. Wright Barbara Brown Taylor Brian McLaren Matthew Sleeth Pope John Paul II and Wendell Berry.\"\n",
      "14,\"Apocalypso (novel)\",\" Apocalypso is a novel by the British author Robert Rankin.\"\n",
      "14,\"Scientometrics (journal)\",\" Scientometrics is a peer-reviewed academic journal in the field of scientometrics. The journal publishes original studies short communications preliminary reports review papers letters to the editor and book reviews on scientometrics. It is published by Akadémiai Kiadó and Springer Science+Business Media and was established in 1978. According to the Journal Citation Reports the journal has a 2011 impact factor of 1.966.\"\n",
      "14,\"Gothic Sports\",\" Gothic Sports is a German manga-styled book created by Anike Hage. It focuses on a young girl named Anya who is adjusting to her new school. When she tries to join various sports teams she's rejected. After she forms her own soccer team thus creating the first Gothic Lolita soccer team. It has been licensed by Tokyopop for English distribution with the first volume being released 1 July 2007. Volume 2 was released on October first and volume 3 was released on January 8 2008.\"\n",
      "14,\"Spits (newspaper)\",\" Sp!ts pronounced Spits is a tabloid format newspaper freely distributed in trains trams and buses in the Netherlands. Its competitor is Metro.\"\n",
      "14,\"Richmond Free Press\",\" The Richmond Free Press is an independent newspaper in Richmond Virginia. Published on a weekly basis it is mainly targeted at the city's African-American community. Its main competitor is the Richmond Times-Dispatch owned by Berkshire Hathaway. Raymond H. Boone is the paper's founder editor and publisher.\"\n",
      "14,\"Summer of the Monkeys\",\" Summer of the Monkeys is a 1976 children's novel written by Wilson Rawls. The book was published by Doubleday (later released by Yearling Books) and was the winner of the William Allen White Book Award and the California Young Reader Medal.\"\n",
      "14,\"Red Cotton Night-Cap Country\",\" Red Cotton Night-Cap Country or Turf and Towers (1873) is a poem in blank verse by Robert Browning. It tells a story of sexual intrigue religious obsession and violent death in contemporary Paris and Normandy closely based on the true story of the death supposedly by suicide of the jewellery heir Antoine Mellerio.\"\n",
      "14,\"The Jukebox Queen of Malta\",\" The Jukebox Queen of Malta is the second novel by American author Nicholas Rinaldi first published in 1999 by Bantam Press.\"\n",
      "14,\"The Banker\",\" The Banker is an English-language monthly international financial affairs publication owned by The Financial Times Ltd. and edited in London. The magazine was first published in January 1926 through founding Editor Brendan Bracken of the Financial News who went on to become the chairman of the Financial Times from 1945-1958.Since its founding the magazine has claimed a dedication to the international perspective through features interviews multi-media applications and events.\"\n",
      "14,\"Donald Duck Adventures\",\" Donald Duck Adventures was a comic book series featuring the adventures of Donald Duck and his nephews Huey Dewey and Louie.\"\n",
      "14,\"Science (journal)\",\" Science also widely referred to as Science Magazine is the academic journal of the American Association for the Advancement of Science (AAAS) and is one of the world's top scientific journals.The peer-reviewed journal first published in 1880 is circulated weekly and has a print subscriber base of around 130000.\"\n",
      "14,\"Hillsboro Free Press\",\" The Hillsboro Free Press is a local weekly newspaper from Hillsboro Kansas. The paper publishes every Wednesday. It is one of two newspapers in the city the other being the Hillsboro Star-Journal.\"\n",
      "14,\"Annals of the Faculty of Law in Belgrade\",\" The Annals of the Faculty of Law in Belgrade (Serbian: Анали Правног факултета у Београду) is a peer-reviewed law review published by the University of Belgrade Faculty of Law. The editor-in-chief is Sima Avramović. The journal solicits articles contributions case and legislation comments debates and book reviews on all aspects of law and social sciences. The journal is accessible on electronic databases such as HeinOnline.\"\n",
      "14,\"The Silly Book\",\" The Silly Book is a children's book by Stoo Hample first published in 1961 and reissued in 2004. It includes silly songs silly names to call people and things silly recipes silly poems silly things to say and silly nothings. Hample's first book it was originally edited by Ursula Nordstrom.\"\n",
      "14,\"Underworld (comic strip)\",\" Underworld is an adult-themed comic strip written and drawn by the artist Kaz since 1992. It runs in many American alternative weeklies such as the New York Press and the SF Bay Guardian. It features regular characters such as Smoking Cat Sam Snuff Creep Rat Nuzzle Petit Mort and others interacting within an archetypal inner-city environment.\"\n",
      "14,\"The Magician: The Secrets of the Immortal Nicholas Flamel\",\" The Magician: The Secrets of the Immortal Nicholas Flamel (often shortened to The Magician) is the second novel in the six book fantasy fiction series The Secrets of the Immortal Nicholas Flamel and is the sequel to The Alchemyst. It was released on 5 June 2008 in the United Kingdom and 24 June 2008 in the United States. It was nominated for an Irish Book of the Year Award The Dublin Airport Authority Irish Children's Book of the Year – Senior Category.\"\n",
      "14,\"Ursule Mirouët\",\" Ursule Mirouët an often overlooked novel belongs to Honoré de Balzac’s great series of 94 novels and short stories La Comédie humaine. First published in 1841 it forms part of his Scènes de la vie de province.The action of the novel takes place in Nemours though with flashbacks to Paris. It is set in the years 1829-1837.\"\n",
      "14,\"Scanners Live in Vain\",\" Scanners Live in Vain is a science fiction short story by Cordwainer Smith (pen name of Paul Linebarger) set in his Instrumentality of Mankind future history. It was originally published in the magazine Fantasy Book in 1950. It was judged by the Science Fiction Writers of America to be one of the finest short stories prior to 1965 and was included in the anthology The Science Fiction Hall of Fame Volume One 1929–1964.\"\n",
      "14,\"Machine of Death\",\" Machine of Death is a 2010 collection of science fiction short stories edited by Ryan North Matthew Bennardo and David Malki.All of the stories center around a device which when provided with a blood sample can identify the way a person will die. The machine relays this information by printing a short word or phrase which serves as the title of each story on a small card.\"\n",
      "14,\"Collected Poems – 2003 edition (Philip Larkin)\",\" This volume edited by Anthony Thwaite contains all of Philip Larkin's poetry published during his lifetime. It consists of the contents of The North Ship The Less Deceived The Whitsun Weddings and High Windows in their original ordering plus two appendices containing all the other poems Larkin published e.g. Aubade.\"\n",
      "14,\"Journal of Biological Chemistry\",\" The Journal of Biological Chemistry is a weekly peer-reviewed scientific journal that was established in 1905. Since 1925 it is published by the American Society for Biochemistry and Molecular Biology. It covers research in areas of biochemistry and molecular biology. The editors-in-chief are Martha Fedor and Herbert Tabor. All its articles are available free after one year of publication. In press articles are available free on its website immediately after acceptance.\"\n",
      "14,\"NME\",\" New Musical Express popularly known by the acronym NME created by Theodore Ingham is a British weekly music journalism publication published since March 1952. It started as a music newspaper and gradually moved toward a magazine format during the 1980s and 90s changing from newsprint in 1998. It was the first British paper to include a singles chart in 14 November 1952 edition. In the 1970s it became the best-selling British music newspaper.\"\n",
      "14,\"The Londoner\",\" The Londoner was a newsletter in the style of a newspaper published by the Mayor of London and delivered free to most households in Greater London United Kingdom.In the words of the Mayor of London's office it was a newsletter for Londoners from the Mayor of London.\"\n",
      "14,\"Formal Aspects of Computing\",\" Formal Aspects of Computing (FAC) is a peer-reviewed scientific journal published by Springer Science+Business Media covering the area of formal methods and associated topics in computer science. The editors-in-chief are Jim Woodcock and Cliff Jones. The journal is associated with BCS-FACS the British Computer Society Formal Aspects of Computing Science Specialist Group. According to the Journal Citation Reports the journal has a 2010 impact factor of 1.170.\"\n",
      "14,\"Hayom Yom\",\" Hayom Yom (Hebrew: היום יום‎ Today is day ...) is a calendar for the Hebrew year of 5703 (1942-3) compiled by Rabbi Menachem Mendel Schneerson at the behest of his father-in-law Rabbi Yosef Yitzchok Schneersohn in the winter of 1942.For each day the calendar prescribed sections of Chumash Tehillim and Tanya for study that day; this practice is known in Chabad-Lubavitch as Chitas (חתת).\"\n",
      "14,\"Swords Against the Shadowland\",\" Swords Against the Shadowland is a fantasy novel by Robin Wayne Bailey featuring Fritz Leiber's sword and sorcery heroes Fafhrd and the Gray Mouser. Chronologically it falls between the first and second volumes of the complete seven volume edition of Leiber's collected stories devoted to the characters. The story is a direct sequel to Ill Met in Lankhmar the last story in Swords and Deviltry and covers some of the same events as The Circle Curse the first story in Swords Against Death.\"\n",
      "14,\"Aruvu Rezuru: Kikaijikake no Yōseitachi\",\" Aruvu Rezuru: Kikaijikake no Yōseitachi (アルヴ・レズル -機械仕掛けの妖精たち- lit. Arve Rezzle: Mechanized Fairies) is a science fiction light novel series by Yū Yamaguchi that began serialization in 2011. It is released through the electronic magazine BOX-AiR an imprint run by Kodansha Box. In December 2011 it was selected out of 11 winners of the New Author Awards to become the first BOX-AiR series to be animated.\"\n",
      "14,\"Tintin (magazine)\",\" Tintin magazine (French: Le Journal de Tintin) (Dutch: Kuifje) was a weekly Franco-Belgian comics magazine of the second half of the 20th century. Subtitled The Journal for the Youth from 7 to 77 it was one of the major publications of the Franco-Belgian comics scene and published such notable series such as Blake and Mortimer Alix and the principal title The Adventures of Tintin.\"\n",
      "14,\"The Tenth Man (Chayefsky play)\",\" The Tenth Man is a 1959 American play.\"\n",
      "14,\"Dramatical Murder\",\" Dramatical Murder (ドラマティカル マーダー Doramatikaru Mādā) styled as DRAMAtical Murder is a Japanese BL visual novel developed and published by Nitro+chiral. It was released on March 23 2012 for Windows PCs as a first press edition with a regular edition released on April 27 2012. A sequel DRAMAtical Murder re:connect (ドラマティカル マーダー リコネクト Doramatikaru Mādā Rikonekuto) was released for Windows PCs on April 26 2013. An anime adaption by studio NAZ will premiere in summer 2014.\"\n",
      "14,\"A Dictionary of Modern English Usage\",\" A Dictionary of Modern English Usage (1926) by Henry Watson Fowler (1858–1933) is a style guide to British English usage pronunciation and writing.\"\n",
      "14,\"Assayad\",\" Assayad is a weekly Arabic news magazine published in Lebanon. It is the first pan-Arab magazine in the country and its headquarters is in Beirut.\"\n",
      "14,\"Loveless (manga)\",\" Loveless (ラブレス Raburesu) is an ongoing fantasy manga by Yun Kōga. It is serialized in the Japanese magazine Monthly Comic Zero Sum by Ichijinsha and collected in eleven tankōbon as of June 2013. Kōga plans to end the manga at fifteen volumes.A 12-episode anime television series adaptation was made by J.C. Staff broadcast in a post-midnight slot on TV Asahi and ABC from April 2005 to June 2005.\"\n",
      "14,\"The American Hebrew\",\" The American Hebrew was a weekly Jewish magazine published in New York City.\"\n",
      "14,\"Montanan (magazine)\",\" The Montanan is the University of Montana's alumni magazine with a circulation of over 80000 making it the largest circulating magazine from Montana.\"\n",
      "14,\"Black Out (novel)\",\" Black Out is a psychological thriller by bestselling author Lisa Unger. It is a standalone novel.\"\n",
      "14,\"Gold Digger (comics)\",\" Gold Digger is a manga-style comic book series written and drawn by Fred Perry and published by Antarctic Press. Fred came up with the initial inspiration for Gold Digger during his tour of duty in the First Gulf War and released the debut oneshot in Antarctic Press' Mangazine in 1991.\"\n",
      "14,\"Dealer's Choice (play)\",\" Dealer's Choice is a play by Patrick Marber first performed at the Royal National Theatre (Cottesloe) in London in February 1995 where it won both the 1995 Evening Standard Award for Best Comedy and the Writers' Guild Award for Best West End Play.It is set in a restaurant in London in the mid-1990s. The action takes place over three acts.\"\n",
      "14,\"Phuket Gazette\",\" The Phuket Gazette is a weekly English-language tabloid newspaper published in Phuket Thailand by The Phuket Gazette Co Ltd. in Koh Kaew. Parichart Utintu is listed as being the editor and Stephen Fein was the paper's News Editor before accepting a severance package in September 2012. The paper was established in 1993 by John Magee and Oranee Hildebrand is the Managing Director. In 2010 Christopher Husted of The Brunei Times became managing editor replacing Nicholas Davies.\"\n",
      "14,\"If I Forget Thee Oh Earth\",\" If I Forget Thee O Earth is a short story written by Arthur C. Clarke and first published in 1951 in the magazine Future. It was subsequently published as part of a short story collection in Expedition to Earth in 1953. The title is taken from Psalm 137:5—If I forget thee O Jerusalem—which consists of the writer lamenting over the destruction of Jerusalem by the Babylonian army.\"\n",
      "14,\"The Lincoln Conspiracy (book)\",\" The Lincoln Conspiracy is a book by David W. Balsiger and Charles E. Sellier Jr. promoting certain conspiracy theories concerning the 1865 assassination of U.S. President Abraham Lincoln.\"\n",
      "14,\"Endocrine Research\",\" Endocrine Research is a peer-reviewed medical journal that covers endocrinology in the broadest context. Subjects of interest include: receptors and mechanism of action of hormones methodological advances in the detection and measurement of hormones; structure and chemical properties of hormones.\"\n",
      "14,\"A Thousand Splendid Suns\",\" A Thousand Splendid Suns is a 2007 novel by Afghan-American author Khaled Hosseini. It is his second following his bestselling 2003 debut The Kite Runner. The book which spans a period of over 50 years from the 1960s to 2003 focuses on the tumultuous lives and relationship of Mariam and Laila two Afghan women. Mariam an illegitimate child suffers from the stigma surrounding her birth and the abuse she faces throughout her marriage.\"\n",
      "14,\"Western People\",\" The Western People is a weekly local newspaper published in Ballina County Mayo in the Republic of Ireland it was first published in 1883. The newspaper was part of the Thomas Crosbie Holdings group. Thomas Crosbie Holdings went into receivership in March 2013. The newspaper was acquired by Landmark Media Investments.\"\n",
      "14,\"Mademoiselle (magazine)\",\" Mademoiselle was a women's magazine first published in 1935 by Street and Smith and later acquired by Condé Nast Publications.Mademoiselle primarily a fashion magazine was also known for publishing short stories by noted authors such as Truman Capote Joyce Carol Oates William Faulkner Tennessee Williams James Baldwin Flannery O'Connor Paul Bowles Jane Bowles Jane Smiley Mary Gordon Paul Theroux Sue Miller Barbara Kingsolver Perri Klass Mona Simpson Alice Munro Harold Brodkey Pam Houston Jean Stafford and Susan Minot. \"\n",
      "14,\"Scoliosis (journal)\",\" Scoliosis (ISSN 1748-7161) is an open-access peer-reviewed online-only medical journal in the field of spinal deformaties. Topics covered include the prevention and treatment of spinal deformities such as scoliosis (spinal curvature).Published by BioMed Central Scoliosis is the official journal of the Society on Scoliosis Orthopaedic and Rehabilitation Treatment and is also affiliated with the International Research Society of Spinal Deformities.\"\n",
      "14,\"Barking in Essex\",\" Barking in Essex is a Black comedy play directed by Harry Burton. It is based on the 2005 script by Clive Exton and made its world premiere at the Wyndham's Theatre in September 2013.\"\n",
      "14,\"Science & Spirit\",\" Science & Spirit is a discontinued American bimonthly magazine that covered scientific stories with an eye toward their spiritual implications. It was launched by the John Templeton Foundation in 1989 as a newsletter converted to a glossy magazine in 1998 then repositioned for a general readership in 2001. In 2003 it was purchased by Heldref Publications though the John Templeton Foundation continued to provide editorial support.\"\n",
      "14,\"The Blithedale Romance\",\" The Blithedale Romance (1852) is Nathaniel Hawthorne's third major romance. In Hawthorne (1879) Henry James called it the lightest the brightest the liveliest of Hawthorne's unhumorous fictions.\"\n",
      "14,\"Razadarit Ayedawbon\",\" Razadarit Ayedawbon (Burmese: ရာဇာဓိရာဇ် အရေးတော်ပုံ) is a Burmese chronicle covering the history of Ramanya from 1287 to 1421. The chronicle consists of accounts of court intrigues rebellions diplomatic missions wars etc. About half of the chronicle is devoted to the reign of King Razadarit (r.\"\n",
      "14,\"The Vinyl Cafe Notebooks\",\" Vinyl Cafe Notebooks: a collection of essays from The Vinyl Cafe (2010) is Stuart McLean's ninth book and each one has been a Canadian bestseller. McLean has sold over 1 million books in Canada. Unlike the other Vinyl Cafe books these are not Dave and Morley stories.Selected from 15 years of radio-show archives and re-edited by the author this eclectic essay collection provides a glimpse into the thoughtful mind at work behind The Vinyl Cafe.\"\n"
     ]
    }
   ],
   "source": [
    "!tail dbpedia_csv/train.csv -n 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the above output, the CSV has 3 fields - Label index, title and abstract. Let us first create a label index to label name mapping and then proceed to preprocess the dataset for ingestion by BlazingText."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will print the labels file (`classes.txt`) to see all possible labels followed by creating an index to label mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company\n",
      "EducationalInstitution\n",
      "Artist\n",
      "Athlete\n",
      "OfficeHolder\n",
      "MeanOfTransportation\n",
      "Building\n",
      "NaturalPlace\n",
      "Village\n",
      "Animal\n",
      "Plant\n",
      "Album\n",
      "Film\n",
      "WrittenWork\n"
     ]
    }
   ],
   "source": [
    "!cat dbpedia_csv/classes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates the mapping from integer indices to class label which will later be used to retrieve the actual class name during inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'Company', '2': 'EducationalInstitution', '3': 'Artist', '4': 'Athlete', '5': 'OfficeHolder', '6': 'MeanOfTransportation', '7': 'Building', '8': 'NaturalPlace', '9': 'Village', '10': 'Animal', '11': 'Plant', '12': 'Album', '13': 'Film', '14': 'WrittenWork'}\n"
     ]
    }
   ],
   "source": [
    "index_to_label = {} \n",
    "with open(\"dbpedia_csv/classes.txt\") as f:\n",
    "    for i,label in enumerate(f.readlines()):\n",
    "        index_to_label[str(i+1)] = label.strip()\n",
    "print(index_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We need to preprocess the training data into **space separated tokenized text** format which can be consumed by `BlazingText` algorithm. Also, as mentioned previously, the class label(s) should be prefixed with `__label__` and it should be present in the same line along with the original sentence. We'll use `nltk` library to tokenize the input sentences from DBPedia dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the nltk tokenizer and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_instance(row):\n",
    "    cur_row = []\n",
    "    label = \"__label__\" + index_to_label[row[0]]  #Prefix the index-ed label with __label__\n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row[1].lower()))\n",
    "    cur_row.extend(nltk.word_tokenize(row[2].lower()))\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `transform_instance` will be applied to each data instance in parallel using python's multiprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(input_file, output_file, keep=1):\n",
    "    all_rows = []\n",
    "    with open(input_file, 'r') as csvinfile:\n",
    "        csv_reader = csv.reader(csvinfile, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            all_rows.append(row)\n",
    "    shuffle(all_rows)\n",
    "    all_rows = all_rows[:int(keep*len(all_rows))]\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "    transformed_rows = pool.map(transform_instance, all_rows)\n",
    "    pool.close() \n",
    "    pool.join()\n",
    "    \n",
    "    with open(output_file, 'w') as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "        csv_writer.writerows(transformed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.21 s, sys: 904 ms, total: 8.12 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Preparing the training dataset\n",
    "\n",
    "# Since preprocessing the whole dataset might take a couple of mintutes,\n",
    "# we keep 20% of the training dataset for this demo.\n",
    "# Set keep to 1 if you want to use the complete dataset\n",
    "preprocess('dbpedia_csv/train.csv', 'dbpedia.train', keep=.2)\n",
    "        \n",
    "# Preparing the validation dataset        \n",
    "preprocess('dbpedia_csv/test.csv', 'dbpedia.validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data preprocessing cell might take a minute to run. After the data preprocessing is complete, we need to upload it to S3 so that it can be consumed by SageMaker to execute training jobs. We'll use Python SDK to upload these two files to the bucket and prefix location that we have set above.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 518 ms, sys: 98.4 ms, total: 616 ms\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "\n",
    "sess.upload_data(path='dbpedia.train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='dbpedia.validation', bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to setup an output location at S3, where the model artifact will be dumped. These artifacts are also the output of the algorithm's traning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now that we are done with all the setup that is needed, we are ready to train our object detector. To begin, let us create a ``sageMaker.estimator.Estimator`` object. This estimator will launch the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 825641698319.dkr.ecr.us-east-2.amazonaws.com/blazingtext:latest (us-east-2)\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print('Using SageMaker BlazingText container: {} ({})'.format(container, region_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the BlazingText model for supervised text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the original implementation of [Word2Vec](https://arxiv.org/pdf/1301.3781.pdf), SageMaker BlazingText provides an efficient implementation of the continuous bag-of-words (CBOW) and skip-gram architectures using Negative Sampling, on CPUs and additionally on GPU[s]. The GPU implementation uses highly optimized CUDA kernels. To learn more, please refer to [*BlazingText: Scaling and Accelerating Word2Vec using Multiple GPUs*](https://dl.acm.org/citation.cfm?doid=3146347.3146354).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides skip-gram and CBOW, SageMaker BlazingText also supports the \"Batch Skipgram\" mode, which uses efficient mini-batching and matrix-matrix operations ([BLAS Level 3 routines](https://software.intel.com/en-us/mkl-developer-reference-fortran-blas-level-3-routines)). This mode enables distributed word2vec training across multiple CPU nodes, allowing almost linear scale up of word2vec computation to process hundreds of millions of words per second. Please refer to [*Parallelizing Word2Vec in Shared and Distributed Memory*](https://arxiv.org/pdf/1604.04661.pdf) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BlazingText also supports a *supervised* mode for text classification. It extends the FastText text classifier to leverage GPU acceleration using custom CUDA kernels. The model can be trained on more than a billion words in a couple of minutes using a multi-core CPU or a GPU, while achieving performance on par with the state-of-the-art deep learning text classification algorithms. For more information, please refer to the [algorithm documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, the following modes are supported by BlazingText on different types instances:\n",
    "\n",
    "|          Modes         \t| cbow (supports subwords training) \t| skipgram (supports subwords training) \t| batch_skipgram \t| supervised |\n",
    "|:----------------------:\t|:----:\t|:--------:\t|:--------------:\t| :--------------:\t|\n",
    "|   Single CPU instance  \t|   ✔  \t|     ✔    \t|        ✔       \t|  ✔  |\n",
    "|   Single GPU instance  \t|   ✔  \t|     ✔    \t|                \t|  ✔ (Instance with 1 GPU only)  |\n",
    "| Multiple CPU instances \t|      \t|          \t|        ✔       \t|     | |\n",
    "\n",
    "Now, let's define the SageMaker `Estimator` with resource configurations and hyperparameters to train Text Classification on *DBPedia* dataset, using \"supervised\" mode on a `c4.4xlarge` instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bt_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.c4.4xlarge',\n",
    "                                         train_volume_size = 30,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to [algorithm documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext_hyperparameters.html) for the complete list of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bt_model.set_hyperparameters(mode=\"supervised\",\n",
    "                            epochs=10,\n",
    "                            min_count=2,\n",
    "                            learning_rate=0.05,\n",
    "                            vector_dim=10,\n",
    "                            early_stopping=True,\n",
    "                            patience=4,\n",
    "                            min_epochs=5,\n",
    "                            word_ngrams=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the hyper-parameters are setup, let us prepare the handshake between our data channels and the algorithm. To do this, we need to create the `sagemaker.session.s3_input` objects from our data channels. These objects are then put in a simple dictionary, which the algorithm consumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='text/plain', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/plain', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our `Estimator` object, we have set the hyper-parameters for this object and we have our data channels linked with the algorithm. The only  remaining thing to do is to train the algorithm. The following command will train the algorithm. Training the algorithm involves a few steps. Firstly, the instance that we requested while creating the `Estimator` classes is provisioned and is setup with the appropriate libraries. Then, the data from our channels are downloaded into the instance. Once this is done, the training job begins. The provisioning and data downloading will take some time, depending on the size of the data. Therefore it might be a few minutes before we start getting training logs for our training jobs. The data logs will also print out Accuracy on the validation data for every epoch after training job has executed `min_epochs`. This metric is a proxy for the quality of the algorithm. \n",
    "\n",
    "Once the job has finished a \"Job complete\" message will be printed. The trained model can be found in the S3 bucket that was setup as `output_path` in the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: blazingtext-2018-12-23-14-23-46-616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-23 14:23:46 Starting - Starting the training job...\n",
      "2018-12-23 14:23:48 Starting - Launching requested ML instances...\n",
      "2018-12-23 14:24:42 Starting - Preparing the instances for training......\n",
      "2018-12-23 14:25:41 Downloading - Downloading input data\n",
      "2018-12-23 14:25:41 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[12/23/2018 14:25:41 WARNING 140631740741440] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[12/23/2018 14:25:41 WARNING 140631740741440] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[12/23/2018 14:25:41 INFO 140631740741440] nvidia-smi took: 0.0251610279083 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[12/23/2018 14:25:41 INFO 140631740741440] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[31m[12/23/2018 14:25:41 INFO 140631740741440] Processing /opt/ml/input/data/train/dbpedia.train . File size: 34 MB\u001b[0m\n",
      "\u001b[31m[12/23/2018 14:25:41 INFO 140631740741440] Processing /opt/ml/input/data/validation/dbpedia.validation . File size: 21 MB\u001b[0m\n",
      "\u001b[31mRead 6M words\u001b[0m\n",
      "\u001b[31mNumber of words:  148577\u001b[0m\n",
      "\u001b[31mLoading validation data from /opt/ml/input/data/validation/dbpedia.validation\u001b[0m\n",
      "\u001b[31mLoaded validation data.\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.968929\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0192  Progress: 61.60%  Million Words/sec: 29.36 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.969643\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0163  Progress: 67.43%  Million Words/sec: 25.99 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0134  Progress: 73.13%  Million Words/sec: 26.54 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.970443\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0103  Progress: 79.46%  Million Words/sec: 24.26 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0074  Progress: 85.18%  Million Words/sec: 24.79 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.971471\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0046  Progress: 90.85%  Million Words/sec: 23.00 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.971714\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0017  Progress: 96.64%  Million Words/sec: 21.78 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.971971\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 21.01 #####\u001b[0m\n",
      "\u001b[31mTraining finished.\u001b[0m\n",
      "\u001b[31mAverage throughput in Million words/sec: 21.01\u001b[0m\n",
      "\u001b[31mTotal training time in seconds: 2.96\n",
      "\u001b[0m\n",
      "\u001b[31m#train_accuracy: 0.9863\u001b[0m\n",
      "\u001b[31mNumber of train examples: 112000\n",
      "\u001b[0m\n",
      "\u001b[31m#validation_accuracy: 0.972\u001b[0m\n",
      "\u001b[31mNumber of validation examples: 70000\u001b[0m\n",
      "\n",
      "2018-12-23 14:26:08 Uploading - Uploading generated training model\n",
      "2018-12-23 14:26:08 Completed - Training job completed\n",
      "Billable seconds: 47\n"
     ]
    }
   ],
   "source": [
    "bt_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting / Inference\n",
    "Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint. This will allow us to make predictions (or inference) from the model. Note that we don't have to host on the same type of instance that we used to train. Because instance endpoints will be up and running for long, it's advisable to choose a cheaper instance for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: blazingtext-2018-12-23-14-26-34-040\n",
      "INFO:sagemaker:Creating endpoint with name blazingtext-2018-12-23-14-23-46-616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "text_classifier = bt_model.deploy(initial_instance_count = 1,instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use JSON format for inference\n",
    "BlazingText supports `application/json` as the content-type for inference. The payload should contain a list of sentences with the key as \"**instances**\" while being passed to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9978227615356445\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Company\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9962173700332642\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__EducationalInstitution\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Convair was an american aircraft manufacturing company which later expanded into rockets and spacecraft.\",\n",
    "            \"Berwick secondary college is situated in the outer melbourne metropolitan suburb of berwick .\"]\n",
    "\n",
    "# using the same nltk tokenizer that we used during data preparation for training\n",
    "tokenized_sentences = [' '.join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "payload = {\"instances\" : tokenized_sentences}\n",
    "\n",
    "response = text_classifier.predict(json.dumps(payload))\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9978227615356445\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Company\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9962173700332642\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__EducationalInstitution\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "setences = [\"I work in a bookshop\"]\n",
    "tokenized_sentences = [' '.join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "payload = {\"instances\" : tokenized_sentences}\n",
    "\n",
    "response = text_classifier.predict(json.dumps(payload))\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the model will return only one prediction, the one with the highest probability. For retrieving the top k predictions, you can set `k` in the configuration as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9978227615356445,\n",
      "      0.0014075090875849128\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Company\",\n",
      "      \"__label__MeanOfTransportation\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9962173700332642,\n",
      "      0.0014661658788099885\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__EducationalInstitution\",\n",
      "      \"__label__OfficeHolder\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "payload = {\"instances\" : tokenized_sentences,\n",
    "          \"configuration\": {\"k\": 2}}\n",
    "\n",
    "response = text_classifier.predict(json.dumps(payload))\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop / Close the Endpoint (Optional)\n",
    "Finally, we should delete the endpoint before we close the notebook if we don't need to keep the endpoint running for serving realtime predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(text_classifier.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
