{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de1c30a2920dec25e75d7020781615f62f5e0d7d"
   },
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import os\n",
    "import gc\n",
    "from keras.preprocessing import sequence,text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#pd.set_option('display.max_colwidth',100)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 210 ms, sys: 50.2 ms, total: 260 ms\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.predictor import csv_serializer\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket='sagemaker-text-movie-sentiment' # put your s3 bucket name here, and create s3 bucket\n",
    "prefix = 'sagemaker/my-own-models'\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "# customize to your bucket where you have stored the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "376108f6e1a22afeba8739d2e12d0aa51fde8dea",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7380"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "### Loading dataset and basic visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_uuid": "cfd09ccff2dbc595ead54e3fd638cfdc3f3089e5",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId  \\\n",
       "0  1         1            \n",
       "1  2         1            \n",
       "2  3         1            \n",
       "3  4         1            \n",
       "4  5         1            \n",
       "\n",
       "                                                                                                                                                                                         Phrase  \\\n",
       "0  A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .   \n",
       "1  A series of escapades demonstrating the adage that what is good for the goose                                                                                                                  \n",
       "2  A series                                                                                                                                                                                       \n",
       "3  A                                                                                                                                                                                              \n",
       "4  series                                                                                                                                                                                         \n",
       "\n",
       "   Sentiment  \n",
       "0  1          \n",
       "1  2          \n",
       "2  2          \n",
       "3  2          \n",
       "4  2          "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.tsv',sep='\\t')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1b7f2e540ea49f1d94ec124b818f2a63c3c66a96",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv('test.tsv',sep='\\t')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "f4509ef7a7adcc7942a6f1acff34c54ce3802d5d",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0  156061    2        \n",
       "1  156062    2        \n",
       "2  156063    2        \n",
       "3  156064    2        \n",
       "4  156065    2        "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.read_csv('sampleSubmission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbe766f446d3bb593acbdf5ef976097c929c7901"
   },
   "source": [
    "**Adding Sentiment column to test datset and joing train and test for preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "293f41b034b63f6526f22fd616877220e19af8e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Sentiment']=-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "277931f786264b67041d060cdf5aec9ace10fd5d",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222352, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222347</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222348</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222349</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222350</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222351</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId                                  Phrase  \\\n",
       "222347  222348    11855       A long-winded , predictable scenario .   \n",
       "222348  222349    11855       A long-winded , predictable scenario     \n",
       "222349  222350    11855       A long-winded ,                          \n",
       "222350  222351    11855       A long-winded                            \n",
       "222351  222352    11855       predictable scenario                     \n",
       "\n",
       "        Sentiment  \n",
       "222347 -999        \n",
       "222348 -999        \n",
       "222349 -999        \n",
       "222350 -999        \n",
       "222351 -999        "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([train,test],ignore_index=True)\n",
    "print(df.shape)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "5c6e9d3571d89ffeba4bbf3a09a027b542499063",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ba69becca5dac25b40fc9c1a421b3d2b93ef7c5"
   },
   "source": [
    "** cleaning review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "44022cdd2e622139943b9e65350dcb89d4d6653e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
    "stemmer=SnowballStemmer('english')\n",
    "lemma=WordNetLemmatizer()\n",
    "from string import punctuation\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "4644cb4452dca89c9870447a9ad828a9fa05098d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_review(review_col):\n",
    "    review_corpus=[]\n",
    "    for i in range(0,len(review_col)):\n",
    "        review=str(review_col[i])\n",
    "        review=re.sub('[^a-zA-Z]',' ',review)\n",
    "        #review=[stemmer.stem(w) for w in word_tokenize(str(review).lower())]\n",
    "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
    "        review=' '.join(review)\n",
    "        review_corpus.append(review)\n",
    "    return review_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "f3aa6294835b8bbba8d324f59b253ab2ec85877a",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>a series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId  \\\n",
       "0  1         1            \n",
       "1  2         1            \n",
       "2  3         1            \n",
       "3  4         1            \n",
       "4  5         1            \n",
       "\n",
       "                                                                                                                                                                                         Phrase  \\\n",
       "0  A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .   \n",
       "1  A series of escapades demonstrating the adage that what is good for the goose                                                                                                                  \n",
       "2  A series                                                                                                                                                                                       \n",
       "3  A                                                                                                                                                                                              \n",
       "4  series                                                                                                                                                                                         \n",
       "\n",
       "   Sentiment  \\\n",
       "0  1           \n",
       "1  2           \n",
       "2  2           \n",
       "3  2           \n",
       "4  2           \n",
       "\n",
       "                                                                                                                                                                             clean_review  \n",
       "0  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story  \n",
       "1  a series of escapade demonstrating the adage that what is good for the goose                                                                                                            \n",
       "2  a series                                                                                                                                                                                \n",
       "3  a                                                                                                                                                                                       \n",
       "4  series                                                                                                                                                                                  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_review']=clean_review(df.Phrase.values)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d4ee11295116391255ecb1ced3ca5054b46a6927"
   },
   "source": [
    "** seperating train and test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "069c27892b11cc1d5a9ac030b67a995532746ea2",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df[df.Sentiment!=-999]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "3f616adc7d6e9a8a12610573762e5ded05fcf96e",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156060</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine effort .</td>\n",
       "      <td>an intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine effort</td>\n",
       "      <td>an intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "156060  156061    8545         \n",
       "156061  156062    8545         \n",
       "156062  156063    8545         \n",
       "156063  156064    8545         \n",
       "156064  156065    8545         \n",
       "\n",
       "                                                        Phrase  \\\n",
       "156060  An intermittently pleasing but mostly routine effort .   \n",
       "156061  An intermittently pleasing but mostly routine effort     \n",
       "156062  An                                                       \n",
       "156063  intermittently pleasing but mostly routine effort        \n",
       "156064  intermittently pleasing but mostly routine               \n",
       "\n",
       "                                                clean_review  \n",
       "156060  an intermittently pleasing but mostly routine effort  \n",
       "156061  an intermittently pleasing but mostly routine effort  \n",
       "156062  an                                                    \n",
       "156063  intermittently pleasing but mostly routine effort     \n",
       "156064  intermittently pleasing but mostly routine            "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=df[df.Sentiment==-999]\n",
    "df_test.drop('Sentiment',axis=1,inplace=True)\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "70afb2e0ee4c0a8eecb8722d4c27a1b8f70e7081",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a606c41b93e32ff05d0443f9eef937e5c1cc3f6f"
   },
   "source": [
    "### Splitting Train dataset into train and 20% validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "26b3d8e058c88e7db59d57347a3ea6e161935128",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text=df_train.clean_review.values\n",
    "test_text=df_test.clean_review.values\n",
    "target=df_train.Sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "26b3d8e058c88e7db59d57347a3ea6e161935128",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=to_categorical(target)\n",
    "#print(train_text.shape,target.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "e782b9cf5191ddcffb98bf97ae14c6ed3e03c1c1",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848,) (124848, 5)\n",
      "(31212,) (31212, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train_text,X_val_text,y_train,y_val=train_test_split(train_text,y,test_size=0.2,stratify=y,random_state=123)\n",
    "print(X_train_text.shape,y_train.shape)\n",
    "print(X_val_text.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a11137fa2b6002edd192dbbe193c8892dbb54a4"
   },
   "source": [
    "### Finding number of unique words in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "e7e9a89d0e29d070a823e18b26519a4994df2bbe",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13732"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words=' '.join(X_train_text)\n",
    "all_words=word_tokenize(all_words)\n",
    "dist=FreqDist(all_words)\n",
    "num_unique_word=len(dist)\n",
    "num_unique_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cc23adc6d5b724da652b4a96c27d0b8d3a1ed3e"
   },
   "source": [
    "### Finding max length of a review in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "3efda4aa9a64a8f586249ec67f9c7a365e0d63aa",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_len=[]\n",
    "for text in X_train_text:\n",
    "    word=word_tokenize(text)\n",
    "    l=len(word)\n",
    "    r_len.append(l)\n",
    "    \n",
    "MAX_REVIEW_LEN=np.max(r_len)\n",
    "MAX_REVIEW_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6eb182fd71e0de1eca715dd412bb0f599a39022"
   },
   "source": [
    "## Building Keras LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "544d2cedfa28005b9ec290944573cbbaf87a05b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = num_unique_word\n",
    "max_words = MAX_REVIEW_LEN\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "num_classes=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c19dcb59cd331384ece2fa2488994cc6e3f95bd"
   },
   "source": [
    "** Tokenize Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "cbbbadc244b31bb2f0513bbd79c867cf976470e8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train_text))\n",
    "X_train = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_val = tokenizer.texts_to_sequences(X_val_text)\n",
    "X_test = tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5aea23744569c4dae3672ef644470c261bb3a97b"
   },
   "source": [
    "** sequence padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "11fc6c41742b656741a4cd2e74a199fc11bb2c93",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848, 48) (31212, 48) (66292, 48)\n"
     ]
    }
   ],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "print(X_train.shape,X_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "230127402dc1492b2c4e20b8b2e0b06e4fab87a1"
   },
   "source": [
    "## 1. LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "eee2bef630ebb6ee8fbb1ca0abf6bc2c2b432c7f",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         1373200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 64)          42240     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,428,021\n",
      "Trainable params: 1,428,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Embedding(max_features,100,mask_zero=True))\n",
    "model1.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
    "model1.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model1.add(Dense(num_classes,activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "6433a2d5da4948a1f29c58d3e451e50c620e6e9c",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/3\n",
      "124848/124848 [==============================] - 280s 2ms/step - loss: 1.0796 - acc: 0.5770 - val_loss: 0.8709 - val_acc: 0.6470\n",
      "Epoch 2/3\n",
      "124848/124848 [==============================] - 523s 4ms/step - loss: 0.8319 - acc: 0.6589 - val_loss: 0.8325 - val_acc: 0.6609\n",
      "Epoch 3/3\n",
      "124848/124848 [==============================] - 890s 7ms/step - loss: 0.7782 - acc: 0.6798 - val_loss: 0.8240 - val_acc: 0.6630\n",
      "CPU times: user 52min 16s, sys: 32min 25s, total: 1h 24min 41s\n",
      "Wall time: 28min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history1=model1.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "2057e1156a660f41f59dfa4d5fd2af55346d0036",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66292/66292 [==============================] - 285s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred1=model1.predict_classes(X_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "5cd6a2c639e4ba2d1401d912907480cc0152d15a",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0  156061    3        \n",
       "1  156062    3        \n",
       "2  156063    2        \n",
       "3  156064    3        \n",
       "4  156065    3        "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.Sentiment=y_pred1\n",
    "sub.to_csv('sub1.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "07d1c0098a602aecefb68f3bafeacbca963ca997"
   },
   "source": [
    "## 2. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "4460dbd9569b4aba47f77785384f095647ed657b",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 48, 100)           1373200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 48, 64)            19264     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,401,429\n",
      "Trainable params: 1,401,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2= Sequential()\n",
    "model2.add(Embedding(max_features,100,input_length=max_words))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1))\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "\n",
    "model2.add(Dense(128,activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "f46171f0090d24271183fb8abfddea51759e9db0",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/1\n",
      "124848/124848 [==============================] - 47s 379us/step - loss: 1.0103 - acc: 0.5965 - val_loss: 0.8659 - val_acc: 0.6473\n",
      "CPU times: user 2min 3s, sys: 12.4 s, total: 2min 15s\n",
      "Wall time: 47.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history2=model2.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=1, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "bcc7476d798449d3bcecb6427445af551f41c1e8",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66292/66292 [==============================] - 24s 369us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred2=model2.predict_classes(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "2463b9a6795979a4a8f1e2724df0f7706f87d646",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0  156061    3        \n",
       "1  156062    3        \n",
       "2  156063    2        \n",
       "3  156064    3        \n",
       "4  156065    3        "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.Sentiment=y_pred2\n",
    "sub.to_csv('sub2.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c15b7e1779fe5f7ec5195329d62fb0a0062a278"
   },
   "source": [
    "## 3. CNN +GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_uuid": "2137f39f26724241879bc63a6fd4e18091302479",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 48, 100)           1373200   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 48, 64)            19264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 24, 128)           74112     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,860,565\n",
      "Trainable params: 1,860,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3= Sequential()\n",
    "model3.add(Embedding(max_features,100,input_length=max_words))\n",
    "model3.add(Conv1D(64,kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(MaxPooling1D(pool_size=2))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(GRU(128,return_sequences=True))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128,activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(5,activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a8d16f09d28d71223ded05b07d91c23a2f775cf",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history3=model3.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dde510827da0c2a8d8f38cb4b17a0e6d6676f3ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred3=model3.predict_classes(X_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ce66c4fe3614d004fcbddc47b119306828b44b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.Sentiment=y_pred3\n",
    "sub.to_csv('sub3.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "382a6fed043c267c47cd3a2ad046ac9e3433efe7"
   },
   "source": [
    "## 4. Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c388a2c19a1818fd5bb5cbfff55b6afe209f2cf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Embedding(max_features, 100, input_length=max_words))\n",
    "model4.add(SpatialDropout1D(0.25))\n",
    "model4.add(Bidirectional(GRU(128)))\n",
    "model4.add(Dropout(0.5))\n",
    "\n",
    "model4.add(Dense(5, activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "209925b26d28c526e8b2b6a58b50aacb5938bb2e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history4=model4.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=12, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a6ebacc09f7b5ba8bada293969360c873b80881",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred4=model4.predict_classes(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44ba9ccda4c83fa57d26605e04d3ce6ebe904d87",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.Sentiment=y_pred4\n",
    "sub.to_csv('sub4.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f1a2ab2bbd194bfe5fd293b385dc9c170b75d90"
   },
   "source": [
    "## 5. Glove word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "99f7b2f8fb1988829f476f06cd012a9de9d82eb5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "def get_embed_mat(EMBEDDING_FILE, max_features,embed_dim):\n",
    "    # word vectors\n",
    "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    # embedding matrix\n",
    "    word_index = tokenizer.word_index\n",
    "    num_words = min(max_features, len(word_index) + 1)\n",
    "    all_embs = np.stack(embeddings_index.values()) #for random init\n",
    "    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n",
    "                                        (num_words, embed_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    max_features = embedding_matrix.shape[0]\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7b92967ad909a7f824c67f36e33f07b9b40987e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding matrix\n",
    "EMBEDDING_FILE = '../input/glove6b100dtxt/glove.6B.100d.txt'\n",
    "embed_dim = 100 #word vector dim\n",
    "embedding_matrix = get_embed_mat(EMBEDDING_FILE,max_features,embed_dim)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "311657e8a90f12dfcd38e176141bf902c43045b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
    "model5.add(SpatialDropout1D(0.25))\n",
    "model5.add(Bidirectional(GRU(128,return_sequences=True)))\n",
    "model5.add(Bidirectional(GRU(64,return_sequences=False)))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(num_classes, activation='softmax'))\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a1532d55f7940ed8a26929a89a279618b9d1846",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history5=model5.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=4, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "275cfcd753c2bfcfaac311dbd43dab0441ced8d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred5=model5.predict_classes(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7eb8ab34a07bc72543aa413f06d38aaf8a8d1336",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.Sentiment=y_pred5\n",
    "sub.to_csv('sub5.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                                                Phrase\n",
      "1  156062    8545        An intermittently pleasing but mostly routine effort\n"
     ]
    }
   ],
   "source": [
    "print(test[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test = model1.predict_classes(X_test[1:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0   15\n",
      "  2514 1678   17  569  807  318]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict_classes(X_test[100:101], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       2, 2, 2, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict_classes([0  ,  0  ,  0  ,  0   , 0   , 0   , 0  ,  0    ,0 ,   0   , 0  ,  0  ,  0 ,   0,\n",
    "     0 ,   0  ,  0  ,  0 ,   0,    0 ,   0 ,   0 ,   0 ,   0 ,   0 ,   0,    0,    0,\n",
    "     0 ,   0 ,   0  ,  0  ,  0 ,   0 ,   0 ,   0,    0,    0,    0 ,   0,    0,   15,\n",
    "  2514, 1678,   17,  569,  807,  318])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90bcf241fed53ebf97eea0073709297cc708d03a"
   },
   "source": [
    "###  combine all output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "c5a10e0955dfaae9da2e16b959b192a8fcb5af5f",
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-45430f77aebf>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-45430f77aebf>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pred_mode = y_pred1 || y_pred2\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sub_all=pd.DataFrame({'model1':y_pred1,'model2':y_pred2})\n",
    "pred_mode = y_pred1 || y_pred2\n",
    "\n",
    "#sub_all.head(20)\n",
    "#pred_mode=sub_all.agg('mode',axis=1)[0].values\n",
    "#print(pred_mode)\n",
    "#sub_all.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36e39edf4690932a64ba8535ef06e2596d46f9ab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_mode=[int(i) for i in pred_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f66247afc2e5710d61427ea2eab00e9c7e4adb81",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.Sentiment=pred_mode\n",
    "sub.to_csv('sub_mode.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26e38be1761b93f8a05c424df6780663efaf3572"
   },
   "source": [
    "Save Model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"LSTM-CNN-Sentiment\"\n",
    "model1.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM-CNN-Sentiment\n"
     ]
    }
   ],
   "source": [
    "!tar czvf model.tar.gz $model_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fObj = open(\"model.tar.gz\", 'rb')\n",
    "key= os.path.join(prefix, model_file_name, 'model.tar.gz')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(fObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'blazingtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3-us-east-2.amazonaws.com/sagemaker-text-movie-sentiment/sagemaker/my-own-models/LSTM-CNN-Sentiment/model.tar.gz\n",
      "arn:aws:sagemaker:us-east-2:420696774360:model/lstm-cnn-sentiment2018-12-31-01-57-56\n",
      "CPU times: user 51 ms, sys: 0 ns, total: 51 ms\n",
      "Wall time: 336 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = model_file_name + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_url = 'https://s3-{}.amazonaws.com/{}/{}'.format(region,bucket,key)\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "print (model_url)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_url,\n",
    "}\n",
    "\n",
    "create_model_response2 = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response2['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm-cnn-EndpointConfig-2018-12-31-08-29-24\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-2:420696774360:endpoint-config/lstm-cnn-endpointconfig-2018-12-31-08-29-24\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'lstm-cnn-EndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'InitialVariantWeight':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm-cnn-Endpoint-2019-01-01-01-46-29\n",
      "arn:aws:sagemaker:us-east-2:420696774360:endpoint/lstm-cnn-endpoint-2019-01-01-01-46-29\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-2:420696774360:endpoint/lstm-cnn-endpoint-2019-01-01-01-46-29\n",
      "Status: InService\n",
      "CPU times: user 102 ms, sys: 2.31 ms, total: 104 ms\n",
      "Wall time: 6min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = 'lstm-cnn-Endpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-83679d6ba63a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpoint_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpoint_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpoint_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_point.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_y' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "point_X = X_test[0]\n",
    "point_X = np.expand_dims(point_X, axis=0)\n",
    "point_y = test_y[0]\n",
    "np.savetxt(\"test_point.csv\", point_X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.content_type = 'text/csv'\n",
    "model1.serializer = csv_serializer\n",
    "model1.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nInvalid type for parameter Body, value: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0  50   6 810]], type: <class 'numpy.ndarray'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-627185859aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n\u001b[1;32m      2\u001b[0m                                       \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text/csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                        Body=payload)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    595\u001b[0m         }\n\u001b[1;32m    596\u001b[0m         request_dict = self._convert_to_request_dict(\n\u001b[0;32m--> 597\u001b[0;31m             api_params, operation_model, context=request_context)\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mservice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyphenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_convert_to_request_dict\u001b[0;34m(self, api_params, operation_model, context)\u001b[0m\n\u001b[1;32m    643\u001b[0m             api_params, operation_model, context)\n\u001b[1;32m    644\u001b[0m         request_dict = self._serializer.serialize_to_request(\n\u001b[0;32m--> 645\u001b[0;31m             api_params, operation_model)\n\u001b[0m\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_host_prefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0mrequest_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'host_prefix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/validate.py\u001b[0m in \u001b[0;36mserialize_to_request\u001b[0;34m(self, parameters, operation_model)\u001b[0m\n\u001b[1;32m    295\u001b[0m                                                     operation_model.input_shape)\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParamValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         return self._serializer.serialize_to_request(parameters,\n\u001b[1;32m    299\u001b[0m                                                      operation_model)\n",
      "\u001b[0;31mParamValidationError\u001b[0m: Parameter validation failed:\nInvalid type for parameter Body, value: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0  50   6 810]], type: <class 'numpy.ndarray'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object"
     ]
    }
   ],
   "source": [
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                      ContentType='text/csv',\n",
    "                                       Body=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
